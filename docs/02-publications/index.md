---
title: Publications
pagination_label: Publications
description: Selected peer-reviewed publications and technical reports.
---

# Publications

This page lists selected publications.

## Multi-Drone System (2025)

Ara√∫jo, A. G., Pizzino, C. A. P., Couceiro, M. S., & Rocha, R. P. (2025). A Multi-Drone System Proof of Concept for Forestry Applications. Drones, 9(2), 80. https://doi.org/10.3390/drones9020080

<div
  style={{
    display: 'flex',
    gap: '1.25rem',
    alignItems: 'flex-start',
    flexWrap: 'wrap',
  }}
>
  <img
    src="/img/pub_2025_drones.png"
    alt="Illustration for: Article title goes here"
    style={{
      width: '40%',
      minWidth: '260px',
      borderRadius: '12px',
    }}
  />

  <div style={{ flex: 1 }}>
    <p>
    This study presents a multi-drone proof of concept for efficient forest mapping and autonomous operation, framed within the context of the OPENSWARM EU Project. The approach leverages state-of-the-art open-source simultaneous localisation and mapping (SLAM) frameworks, like LiDAR (Light Detection And Ranging) Inertial Odometry via Smoothing and Mapping (LIO-SAM), and Distributed Collaborative LiDAR SLAM Framework for a Robotic Swarm (DCL-SLAM), seamlessly integrated within the MRS UAV System and Swarm Formation packages. This integration is achieved through a series of procedures compliant with Robot Operating System middleware (ROS), including an auto-tuning particle swarm optimisation method for enhanced flight control and stabilisation, which is crucial for autonomous operation in challenging environments. Field experiments conducted in a forest with multiple drones demonstrate the system‚Äôs ability to navigate complex terrains as a coordinated swarm, accurately and collaboratively mapping forest areas. Results highlight the potential of this proof of concept, contributing to the development of scalable autonomous solutions for forestry management. The findings emphasise the significance of integrating multiple open-source technologies to advance sustainable forestry practices using swarms of drones.
    Keywords: multi-drone system; drones for forestry; forest mapping; swarms of drones
    </p>

  </div>
</div>

<Button label="üìÑ Multi-Drone System" link="/files/2025_drones.pdf" />{' '}


## Construction Pilot (2024)

Couceiro, M. S., Yalcinkaya, B., Pizzino, C., & Garcia, R. B. (2024). ‚ÄúEstablishing an On-Site Construction Pilot for Collaboration Between Humans and Heavy-Duty Robots.‚Äù, https://doi.org/10.22260/ICRA2024/0003.



<div
  style={{
    display: 'flex',
    gap: '1.25rem',
    alignItems: 'flex-start',
    flexWrap: 'wrap',
  }}
>
  <img
    src="/img/pub_2025_icra.png"
    alt="Illustration for: Article title goes here"
    style={{
      width: '40%',
      minWidth: '260px',
      borderRadius: '12px',
    }}
  />

  <div style={{ flex: 1 }}>
    <p>
        Simultaneous Localization and Mapping (SLAM) is a fundamental problem in the field of robotics, enabling autonomous robots to navigate and create maps of unknown environments. Nevertheless, the SLAM methods that use cameras face problems in maintaining accurate localization over extended periods across various challenging conditions and scenarios. Following advances in neuroscience, we propose NeoSLAM, a novel long-term visual SLAM, which uses computational models of the brain to deal with this problem. Inspired by the human neocortex, NeoSLAM is based on a hierarchical temporal memory model that has the potential to identify temporal sequences of spatial patterns using sparse distributed representations. Being known to have a high representational capacity and high tolerance to noise, sparse distributed representations have several properties, enabling the development of a novel neuroscience-based loop-closure detector that allows for real-time performance, especially in resource-constrained robotic systems. The proposed method has been thoroughly evaluated in terms of environmental complexity by using a wheeled robot deployed in the field and demonstrated that the accuracy of loop-closure detection was improved compared with the traditional RatSLAM system.
    </p>

  </div>
</div>

<Button label="üìÑ Construction Pilot" link="/files/2024_icra.pdf" />{' '}


## NeoSLAM (2024)

Pizzino, C. A. P., Costa, R. R., Mitchell, D., & Vargas, P. A. (2024). NeoSLAM: Long-Term SLAM Using Computational Models of the Brain. Sensors, 24(4), 1143. https://doi.org/10.3390/s24041143



<div
  style={{
    display: 'flex',
    gap: '1.25rem',
    alignItems: 'flex-start',
    flexWrap: 'wrap',
  }}
>
  <img
    src="/img/sensors-24-01143-g001.png"
    alt="Illustration for: Article title goes here"
    style={{
      width: '40%',
      minWidth: '260px',
      borderRadius: '12px',
    }}
  />

  <div style={{ flex: 1 }}>
    <p>
        Simultaneous Localization and Mapping (SLAM) is a fundamental problem in the field of robotics, enabling autonomous robots to navigate and create maps of unknown environments. Nevertheless, the SLAM methods that use cameras face problems in maintaining accurate localization over extended periods across various challenging conditions and scenarios. Following advances in neuroscience, we propose NeoSLAM, a novel long-term visual SLAM, which uses computational models of the brain to deal with this problem. Inspired by the human neocortex, NeoSLAM is based on a hierarchical temporal memory model that has the potential to identify temporal sequences of spatial patterns using sparse distributed representations. Being known to have a high representational capacity and high tolerance to noise, sparse distributed representations have several properties, enabling the development of a novel neuroscience-based loop-closure detector that allows for real-time performance, especially in resource-constrained robotic systems. The proposed method has been thoroughly evaluated in terms of environmental complexity by using a wheeled robot deployed in the field and demonstrated that the accuracy of loop-closure detection was improved compared with the traditional RatSLAM system.
    </p>

  </div>
</div>

<Button label="üìÑ NeoSLAM" link="/files/2024_sensors.pdf" />{' '}



